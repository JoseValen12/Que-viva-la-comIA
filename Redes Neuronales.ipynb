{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b631fc0-b0ae-4780-adf7-3411cc56a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random, pathlib\n",
    "from collections import defaultdict\n",
    "\n",
    "random.seed(1337)  # Fijamos la semilla para que las selecciones sean reproducibles.\n",
    "\n",
    "src_dir = \"PruebaDataset\"            # Indicamos la carpeta de origen con subcarpetas por clase.\n",
    "dst_dir = \"PruebaDataset_balanced\"   # Indicamos la carpeta de destino donde crearemos el dataset balanceado.\n",
    "extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}  # Definimos las extensiones de imagen permitidas.\n",
    "\n",
    "# 1) Recolectamos rutas por clase.\n",
    "files_by_class = defaultdict(list)\n",
    "for cls in sorted(os.listdir(src_dir)):\n",
    "    cpath = os.path.join(src_dir, cls)\n",
    "    if not os.path.isdir(cpath):\n",
    "        continue  # Ignoramos entradas que no sean directorios de clase.\n",
    "    for root, _, files in os.walk(cpath):\n",
    "        for f in files:\n",
    "            if pathlib.Path(f).suffix.lower() in extensions:\n",
    "                files_by_class[cls].append(os.path.join(root, f))  # AÃ±adimos la ruta de cada imagen vÃ¡lida.\n",
    "\n",
    "# 2) Calculamos cuÃ¡ntas imÃ¡genes hay por clase y definimos N objetivo por clase.\n",
    "counts = {cls: len(v) for cls, v in files_by_class.items()}\n",
    "min_count = min(counts.values())  # Obtenemos el mÃ­nimo por si queremos usarlo como lÃ­mite inferior.\n",
    "N = 100  # Definimos el nÃºmero de muestras por clase, ajustable segÃºn disponibilidad por clase.\n",
    "\n",
    "print(\"ImÃ¡genes por clase:\", counts)  # Mostramos el conteo de imÃ¡genes por clase para diagnÃ³stico.\n",
    "print(f\"Usando N={N} por clase\")  # Confirmamos el N elegido por clase.\n",
    "\n",
    "# 3) Creamos la carpeta de destino limpia.\n",
    "if os.path.exists(dst_dir):\n",
    "    shutil.rmtree(dst_dir)  # Eliminamos el destino si existÃ­a para evitar mezclas previas.\n",
    "os.makedirs(dst_dir, exist_ok=True)  # Creamos la carpeta de destino desde cero.\n",
    "\n",
    "# 4) Definimos helper para enlazar o copiar archivos segÃºn el sistema.\n",
    "def link_or_copy(src, dst):\n",
    "    try:\n",
    "        os.symlink(os.path.abspath(src), dst)  # Creamos un enlace simbÃ³lico para ahorrar espacio cuando sea posible.\n",
    "    except Exception:\n",
    "        shutil.copy2(src, dst)  # Copiamos fÃ­sicamente el archivo si no podemos crear el enlace.\n",
    "\n",
    "# 5) Seleccionamos N imÃ¡genes aleatorias por clase y las escribimos en el destino.\n",
    "for cls, paths in files_by_class.items():\n",
    "    random.shuffle(paths)  # Barajamos las rutas para muestrear aleatoriamente.\n",
    "    keep = paths[:N]  # Tomamos las primeras N rutas tras el barajado.\n",
    "    out_cls = os.path.join(dst_dir, cls)\n",
    "    os.makedirs(out_cls, exist_ok=True)  # Creamos la subcarpeta de la clase en el destino.\n",
    "    for i, p in enumerate(keep):\n",
    "        ext = pathlib.Path(p).suffix.lower()\n",
    "        dst_path = os.path.join(out_cls, f\"{cls}_{i:05d}{ext}\")  # Generamos un nombre de archivo estable y ordenable.\n",
    "        link_or_copy(p, dst_path)  # Enlazamos o copiamos la imagen al destino.\n",
    "\n",
    "print(\"âœ“ Dataset balanceado creado en:\", dst_dir)  # Indicamos finalizaciÃ³n y la ruta del dataset balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23292b01-e1b4-4598-85d7-98195d3f1fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11850 images belonging to 120 classes.\n",
      "Clases detectadas en TRAIN: 120\n",
      "['Aguacate', 'Anacardos', 'Banana', 'Berberechos', 'CalabacÃ­n', 'Calabaza', 'Canela', 'CanÃ³nigos', 'Carne Cerdo', 'Carne Conejo', 'Carne Cordero', 'Carne Pavo', 'Carne Ternera', 'Carne picada', 'Chorizo', 'Cilantro', 'Clavo', 'Coliflor', 'Curry', 'Cuscus', 'Espaguetis', 'Espinacas', 'Fideos', 'Gambas', 'Garbanzos', 'Grosellas', 'Guisantes', 'Hierbabuena', 'Jamon iberico', 'Levadura', 'Lima', 'LimÃ³n', 'Mantequilla', 'Mayonesa', 'Mejillones', 'Melocotones', 'MelÃ³n', 'Membrillo', 'Merluza', 'Miel', 'Mora', 'Morcilla', 'Mostaza', 'Naranja', 'Nata lÃ­quida', 'Nueces', 'Nuez moscada', 'NÃ­scalos', 'OrÃ©gano', 'Pechuga de pollo', 'Salmon', 'Tomillo', 'Zanahoria', 'aceitunas', 'acelgas', 'ajo', 'albahaca', 'alcachofa', 'almejas', 'almendras', 'apio', 'arroz', 'atun fresco', 'avellanas', 'azucar', 'bacalao', 'berenjena', 'boniato', 'boquerones', 'brocoli', 'calamares', 'cebollas', 'cerezas', 'champinones', 'chirimoya', 'chocolate', 'col', 'huevos', 'judÃ­as verdes', 'langostinos', 'laurel', 'leche', 'lechuga', 'lentejas', 'manzana', 'pan rallado', 'pasta macarrones', 'patata', 'pepino', 'pera', 'perejil', 'pimentÃ³n', 'pimienta blanca', 'pimienta negra', 'pimiento amarillo', 'pimiento rojo', 'pimiento verde', 'pistacho', 'piÃ±ones', 'platano', 'puerro', 'pulpo', 'queso fresco', 'queso manchego', 'quinoa', 'rabanitos', 'romero', 'rucula', 'sal', 'sandia', 'sardinas', 'sepia', 'setas variadas', 'tomate', 'tomate cherry', 'uva', 'vinagre balsamico', 'vino blanco', 'vino tinto', 'yogur natural']\n",
      "Found 11850 images belonging to 120 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                         </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape                </span>â”ƒ<span style=\"font-weight: bold\">         Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                â”‚               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">245,880</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)              â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                â”‚      \u001b[38;5;34m23,564,800\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)                    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                â”‚               \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 â”‚         \u001b[38;5;34m245,880\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,810,680</span> (90.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,810,680\u001b[0m (90.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">245,880</span> (960.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m245,880\u001b[0m (960.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> (89.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,564,800\u001b[0m (89.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Entrenamiento inicial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\anaconda3\\envs\\Proyecto\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "C:\\Users\\Jose\\anaconda3\\envs\\Proyecto\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m 56/371\u001b[0m \u001b[32mâ”â”â”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m9:01\u001b[0m 2s/step - accuracy: 0.0402 - loss: 5.2050"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) ConfiguraciÃ³n reproducible.\n",
    "# -----------------------------------------------------------------------------\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Silenciamos los logs de TensorFlow para mantener la salida limpia.\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Generadores de datos (consistentes con ResNet50V2).\n",
    "# -----------------------------------------------------------------------------\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
    "\n",
    "img_size = (256, 256)\n",
    "batch_size = 32\n",
    "target_shape = (*img_size, 3)\n",
    "\n",
    "# Creamos el generador de datos con aumentaciÃ³n para el entrenamiento.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=resnet_preprocess\n",
    ")\n",
    "\n",
    "# Creamos el generador de datos para validaciÃ³n solo con preprocesamiento.\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=resnet_preprocess\n",
    ")\n",
    "\n",
    "# Cargamos las imÃ¡genes de entrenamiento desde la carpeta correspondiente.\n",
    "data_gen_entrenamiento = train_datagen.flow_from_directory(\n",
    "    \"Dataset\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "# Obtenemos los nombres de las clases y la cantidad total detectada.\n",
    "class_names = list(data_gen_entrenamiento.class_indices.keys())\n",
    "num_classes = len(class_names)\n",
    "print(\"Clases detectadas en TRAIN:\", num_classes)\n",
    "print(class_names)\n",
    "\n",
    "#with open(\"class_names.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#    json.dump(class_names, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# Creamos el generador de validaciÃ³n, forzando el mismo orden de clases.\n",
    "data_gen_pruebas = valid_datagen.flow_from_directory(\n",
    "    \"Dataset\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    classes=class_names\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) DefiniciÃ³n del modelo (ResNet50V2 base + capa de clasificaciÃ³n).\n",
    "# -----------------------------------------------------------------------------\n",
    "def crear_modelo_resnet(input_shape, n_classes):\n",
    "    from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "    # Cargamos la base preentrenada sin la parte superior.\n",
    "    base = ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape,\n",
    "        pooling=\"avg\",\n",
    "        name=\"resnet50v2\"\n",
    "    )\n",
    "    base.trainable = False  # Mantenemos la base congelada inicialmente.\n",
    "\n",
    "    # Definimos la arquitectura del modelo completo.\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # Compilamos el modelo con Adam y entropÃ­a cruzada categÃ³rica.\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) CreaciÃ³n del modelo.\n",
    "# -----------------------------------------------------------------------------\n",
    "model = crear_modelo_resnet(target_shape, num_classes)\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) DefiniciÃ³n de callbacks.\n",
    "# -----------------------------------------------------------------------------\n",
    "callbacks_iniciales = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        min_delta=0.001\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Entrenamiento inicial con la base congelada.\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"ğŸš€ Entrenamiento inicial...\")\n",
    "historial = model.fit(\n",
    "    data_gen_entrenamiento,\n",
    "    epochs=30,\n",
    "    validation_data=data_gen_pruebas,\n",
    "    callbacks=callbacks_iniciales,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) Fine-tuning: descongelamos las capas superiores de la base.\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"ğŸ”§ Fine-tuning...\")\n",
    "\n",
    "base_model = model.get_layer(\"resnet50v2\")\n",
    "N = 30  # NÃºmero de capas superiores a descongelar.\n",
    "for layer in base_model.layers[-N:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Recompilamos con una tasa de aprendizaje mÃ¡s baja.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks_ft = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=4,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "historial_ft = model.fit(\n",
    "    data_gen_entrenamiento,\n",
    "    epochs=10,\n",
    "    validation_data=data_gen_pruebas,\n",
    "    callbacks=callbacks_ft,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8) EvaluaciÃ³n final del modelo.\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"ğŸ“Š EvaluaciÃ³n final en validaciÃ³n:\")\n",
    "val_loss, val_acc = model.evaluate(data_gen_pruebas, verbose=0)\n",
    "print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "#model.save(\"modelo.h5\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9) VisualizaciÃ³n de las curvas de entrenamiento.\n",
    "# -----------------------------------------------------------------------------\n",
    "acc = historial.history.get('accuracy', []) + historial_ft.history.get('accuracy', [])\n",
    "val_acc = historial.history.get('val_accuracy', []) + historial_ft.history.get('val_accuracy', [])\n",
    "loss = historial.history.get('loss', []) + historial_ft.history.get('loss', [])\n",
    "val_loss_hist = historial.history.get('val_loss', []) + historial_ft.history.get('val_loss', [])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('PrecisiÃ³n del modelo.')\n",
    "plt.ylabel('PrecisiÃ³n.')\n",
    "plt.xlabel('Ã‰poca.')\n",
    "plt.legend(['Entrenamiento', 'ValidaciÃ³n'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss_hist)\n",
    "plt.title('PÃ©rdida del modelo.')\n",
    "plt.ylabel('PÃ©rdida.')\n",
    "plt.xlabel('Ã‰poca.')\n",
    "plt.legend(['Entrenamiento', 'ValidaciÃ³n'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 10) CÃ¡lculo de mÃ©tricas por clase y matriz de confusiÃ³n.\n",
    "# -----------------------------------------------------------------------------\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Obtenemos las predicciones sobre el conjunto de validaciÃ³n.\n",
    "y_true = data_gen_pruebas.classes\n",
    "y_prob = model.predict(data_gen_pruebas, verbose=1)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "# Generamos el informe de clasificaciÃ³n por clase.\n",
    "labels_all = np.arange(num_classes)\n",
    "\n",
    "print(\"\\nğŸ“„ Classification report por clase:\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=labels_all,\n",
    "    target_names=class_names,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Calculamos la matriz de confusiÃ³n.\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_all)\n",
    "print(\"\\nğŸ”¢ Matriz de confusiÃ³n (filas=verdadero, columnas=predicho):\")\n",
    "print(cm)\n",
    "\n",
    "# Calculamos la exactitud por clase.\n",
    "cm_diag = np.diag(cm)\n",
    "support = cm.sum(axis=1)\n",
    "acc_per_class = cm_diag / np.maximum(support, 1)\n",
    "\n",
    "print(\"\\nâœ… Exactitud por clase:\")\n",
    "for name, acc_c, sup in zip(class_names, acc_per_class, support):\n",
    "    print(f\" - {name:<20s} acc={acc_c:7.4f}  soporte={sup}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a7f9c-3d01-4166-a34d-eae08285df76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
