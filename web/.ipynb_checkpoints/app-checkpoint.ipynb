{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff04c42-d605-43dd-b469-59a5703e8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify, render_template, Response\n",
    "import os, io, time, sqlite3, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
    "import re, unicodedata\n",
    "import math\n",
    "\n",
    "# -----------------------------\n",
    "# RUTAS DE ARCHIVOS.\n",
    "# -----------------------------\n",
    "MODEL_PATH = \"modelo.h5\"\n",
    "CLASS_NAMES_PATH = \"class_names.json\"\n",
    "RECIPES_PATH = \"procesado_total.ods\"  # Indicamos el dataset de recetas en formato ODS.\n",
    "DB_PATH = \"data.db\"\n",
    "\n",
    "# -----------------------------\n",
    "# FLASK APP.\n",
    "# -----------------------------\n",
    "app = Flask(__name__, template_folder=\"templates\", static_folder=\"static\")\n",
    "app.config[\"JSON_AS_ASCII\"] = False  # Permitimos UTF-8 en respuestas JSON para no escapar acentos.\n",
    "\n",
    "# -----------------------------\n",
    "# CARGA MODELO + CLASES.\n",
    "# -----------------------------\n",
    "model = load_model(MODEL_PATH, compile=False)  # Cargamos el modelo sin recompilar para servir inferencias.\n",
    "with open(CLASS_NAMES_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "    CLASS_NAMES = json.load(f)  # Cargamos la lista de clases en el mismo orden que el modelo.\n",
    "\n",
    "# -----------------------------\n",
    "# RECETAS (ODS) + SQLITE.\n",
    "# -----------------------------\n",
    "RECIPES_DF = None  # Diferimos la carga hasta la inicialización controlada.\n",
    "\n",
    "def init_db():\n",
    "    # Creamos tablas si no existen para registrar predicciones e ingredientes.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS predictions (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            image_name TEXT,\n",
    "            top_class TEXT,\n",
    "            score REAL,\n",
    "            created_at INTEGER\n",
    "        )\n",
    "        \"\"\")\n",
    "        # Añadimos catálogo de ingredientes seleccionados por el usuario.\n",
    "        con.execute(\"\"\"\n",
    "        CREATE TABLE IF NOT EXISTS ingredients (\n",
    "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "            name TEXT UNIQUE,\n",
    "            created_at INTEGER\n",
    "        )\n",
    "        \"\"\")\n",
    "        con.commit()\n",
    "\n",
    "def save_ingredient(name: str):\n",
    "    # Insertamos el ingrediente si no existía previamente para mantener idempotencia.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        cur = con.execute(\n",
    "            \"INSERT OR IGNORE INTO ingredients(name, created_at) VALUES(?, ?)\",\n",
    "            (name.strip(), int(time.time()))\n",
    "        )\n",
    "        con.commit()\n",
    "        return cur.lastrowid\n",
    "\n",
    "def delete_ingredient(name: str):\n",
    "    # Eliminamos un ingrediente por nombre ignorando mayúsculas/minúsculas.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        cur = con.execute(\n",
    "            \"DELETE FROM ingredients WHERE LOWER(name) = LOWER(?)\",\n",
    "            (name.strip(),)\n",
    "        )\n",
    "        con.commit()\n",
    "        return cur.rowcount\n",
    "\n",
    "def list_ingredients():\n",
    "    # Listamos ingredientes guardados ordenados por fecha de creación descendente.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        cur = con.execute(\"SELECT id, name, created_at FROM ingredients ORDER BY created_at DESC\")\n",
    "        rows = cur.fetchall()\n",
    "    return [dict(id=r[0], name=r[1], created_at=r[2]) for r in rows]\n",
    "\n",
    "def _normalize(text: str) -> str:\n",
    "    # Normalizamos a ASCII, minúsculas y espaciado para comparaciones robustas.\n",
    "    import re, unicodedata\n",
    "    t = unicodedata.normalize(\"NFKD\", str(text or \"\")).encode(\"ascii\",\"ignore\").decode(\"ascii\")\n",
    "    t = t.lower()\n",
    "    t = re.sub(r\"[^a-z0-9% ]+\", \" \", t)\n",
    "    t = re.sub(r\"\\s+\", \" \", t).strip()\n",
    "    return t\n",
    "\n",
    "# Catálogo fijo de alérgenos mapeado a sinónimos o ingredientes frecuentes.\n",
    "# Ajustamos las claves a etiquetas presentes en el dataset para reducir falsos positivos.\n",
    "ALLERGENS = {\n",
    "    \"gluten\": [\n",
    "        \"Espaguetis\", \"Fideos\", \"Cuscus\", \"pan rallado\", \"pasta macarrones\",\n",
    "    ],\n",
    "    \"frutos_secos\": [\n",
    "        \"Anacardos\", \"almendras\", \"avellanas\", \"Nueces\", \"pistacho\", \"piñones\",\n",
    "    ],\n",
    "    \"lactosa\": [\n",
    "        \"Mantequilla\", \"Nata líquida\", \"leche desnatada\", \"leche entera\",\n",
    "        \"leche semidesnatada\", \"queso fresco\", \"queso manchego\", \"yogur natural\",\n",
    "    ],\n",
    "    \"huevo\": [\n",
    "        \"huevos\", \"Mayonesa\", \"unidad de huevo\", \"huevo,\", \"huevos,\" , \"huevo\", \",2 huevos,\"\n",
    "    ],\n",
    "    \"marisco\": [\n",
    "        \"Gambas\", \"langostinos\",\n",
    "    ],\n",
    "    \"moluscos\": [\n",
    "        \"Berberechos\", \"Mejillones\", \"almejas\", \"sepia\", \"calamares\", \"pulpo\",\n",
    "    ],\n",
    "    \"pescado\": [\n",
    "        \"Salmon\", \"Merluza\", \"atun fresco\", \"bacalao\", \"boquerones\", \"sardinas\",\n",
    "    ],\n",
    "    \"apio\": [\"apio\"],\n",
    "    \"mostaza\": [\"Mostaza\"],\n",
    "}\n",
    "\n",
    "# Frases que implican ausencia explícita del alérgeno y que no deberían excluir la receta.\n",
    "EXCEPTIONS = [\n",
    "    \"sin gluten\", \"gluten free\", \"libre de gluten\",\n",
    "    \"sin lactosa\", \"lactose free\", \"libre de lactosa\",\n",
    "    \"sin huevo\", \"egg free\",\n",
    "    \"sin frutos secos\", \"nut free\",\n",
    "    \"sin marisco\", \"sin moluscos\", \"sin pescado\",\n",
    "    \"sin apio\", \"sin mostaza\",\n",
    "]\n",
    "\n",
    "# Frases específicas para evitar coincidencias ambiguas que no son alérgeno real.\n",
    "NEGATIVE_PHRASES = [\n",
    "    \"nuez moscada\",\n",
    "]\n",
    "\n",
    "def exclude_allergies_df(df, selected_keys):\n",
    "    \"\"\"\n",
    "    Excluimos recetas que contengan cualquier término asociado a las alergias seleccionadas\n",
    "    buscando en columnas de texto clave, respetando excepciones de tipo 'sin X' y frases negativas.\n",
    "    \"\"\"\n",
    "    import re\n",
    "    if df is None or df.empty or not selected_keys:\n",
    "        return df\n",
    "\n",
    "    cols = [c for c in [\"Ingredientes\", \"Lista de ingredientes\", \"Nombre\", \"Categoria\"] if c in df.columns]\n",
    "    if not cols:\n",
    "        return df\n",
    "\n",
    "    corpus = df[cols].astype(str).fillna(\"\").agg(\" \".join, axis=1)\n",
    "    corpus_norm = corpus.map(_normalize)\n",
    "\n",
    "    # Detectamos excepciones explícitas para no filtrar esas filas.\n",
    "    if EXCEPTIONS:\n",
    "        exceptions_rx = re.compile(r\"|\".join(map(re.escape, map(_normalize, EXCEPTIONS))))\n",
    "        has_exception = corpus_norm.str.contains(exceptions_rx, na=False)\n",
    "    else:\n",
    "        has_exception = False\n",
    "\n",
    "    # Detectamos frases negativas para minimizar falsos positivos.\n",
    "    if NEGATIVE_PHRASES:\n",
    "        neg_rx = re.compile(r\"|\".join(map(re.escape, map(_normalize, NEGATIVE_PHRASES))))\n",
    "        has_negative = corpus_norm.str.contains(neg_rx, na=False)\n",
    "    else:\n",
    "        has_negative = False\n",
    "\n",
    "    # Construimos patrón OR con todos los términos de las claves elegidas.\n",
    "    terms = []\n",
    "    for k in selected_keys:\n",
    "        terms.extend(ALLERGENS.get(k, []))\n",
    "\n",
    "    terms_norm = sorted({_normalize(t) for t in terms if t})\n",
    "    if not terms_norm:\n",
    "        return df\n",
    "\n",
    "    # Coincidimos por palabra completa para reducir falsos positivos.\n",
    "    allergen_rx = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, terms_norm)) + r\")\\b\")\n",
    "\n",
    "    has_allergen = corpus_norm.str.contains(allergen_rx, na=False)\n",
    "\n",
    "    # Aplicamos la regla final combinando alérgenos, excepciones y frases negativas.\n",
    "    if isinstance(has_exception, bool):\n",
    "        safe_mask = ~(has_allergen) | (has_negative)\n",
    "    else:\n",
    "        safe_mask = ~(has_allergen & ~has_exception) | (has_negative)\n",
    "\n",
    "    return df.loc[safe_mask]\n",
    "\n",
    "def get_saved_ingredients():\n",
    "    # Obtenemos todos los ingredientes guardados por el usuario.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        cur = con.execute(\"SELECT name FROM ingredients\")\n",
    "        return [r[0] for r in cur.fetchall()]\n",
    "\n",
    "def recipes_for_ingredients_df(ingredients: list, limit: int = 20):\n",
    "    # Buscamos recetas que contengan todos los ingredientes indicados en campos relevantes.\n",
    "    df = RECIPES_DF\n",
    "    if df is None or not ingredients:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    parts = []\n",
    "    for c in [\"Ingredientes\", \"Lista de ingredientes\", \"Nombre\", \"Categoria\"]:\n",
    "        if c in df.columns:\n",
    "            parts.append(df[c].astype(str))\n",
    "    if not parts:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    corpus = parts[0]\n",
    "    for s in parts[1:]:\n",
    "        corpus = corpus.str.cat(s, sep=\" \", na_rep=\"\")\n",
    "\n",
    "    norm_series = corpus.fillna(\"\").map(_normalize)\n",
    "\n",
    "    mask = pd.Series(True, index=df.index)\n",
    "    for ing in ingredients:\n",
    "        term = re.escape(_normalize(ing))\n",
    "        mask &= norm_series.str.contains(term, na=False)\n",
    "\n",
    "    out = df.loc[mask]\n",
    "    cols = [c for c in [\"Id\", \"Categoria\", \"Nombre\", \"Valoracion\", \"Ingredientes\", \"Lista de ingredientes\", \"Link_receta\"] if c in df.columns]\n",
    "    return out[cols].head(limit).reset_index(drop=True)\n",
    "\n",
    "def _df_records_clean(df):\n",
    "    # Limpiamos valores no finitos y NaN para serialización JSON estable.\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "\n",
    "    # Convertimos columnas numéricas a tipos nativos manejando no finitos.\n",
    "    for c in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[c]):\n",
    "            df[c] = df[c].apply(lambda v: (None if (v is None or (isinstance(v, float) and not math.isfinite(v))) else v))\n",
    "\n",
    "    def _to_builtin(v):\n",
    "        if v is None or isinstance(v, (bool, np.bool_)): return bool(v) if v is not None else None\n",
    "        if isinstance(v, (np.integer,)):                 return int(v)\n",
    "        if isinstance(v, (np.floating,)):\n",
    "            f = float(v)\n",
    "            return f if math.isfinite(f) else None\n",
    "        return v\n",
    "\n",
    "    for c in df.columns:\n",
    "        df[c] = df[c].map(_to_builtin)\n",
    "\n",
    "    return df.to_dict(orient=\"records\")\n",
    "\n",
    "def load_recipes():\n",
    "    # Cargamos el ODS con engine odf, normalizamos nombres de columnas y validamos requeridas.\n",
    "    df = pd.read_excel(RECIPES_PATH, engine=\"odf\")\n",
    "    df.columns = [str(c).strip() for c in df.columns]\n",
    "    for col in [\"Id\", \"Categoria\", \"Nombre\"]:\n",
    "        if col not in df.columns:\n",
    "            raise RuntimeError(f\"Falta la columna requerida en recetas: {col}\")\n",
    "    return df\n",
    "\n",
    "def init_app_once():\n",
    "    \"\"\"\n",
    "    Evitamos doble inicialización cuando Flask usa el reloader en modo debug.\n",
    "    \"\"\"\n",
    "    global RECIPES_DF\n",
    "    if getattr(app, \"_inited\", False):\n",
    "        return\n",
    "    init_db()\n",
    "    RECIPES_DF = load_recipes()\n",
    "    app._inited = True\n",
    "\n",
    "# Inicializamos de forma segura considerando el reloader de Werkzeug.\n",
    "if os.environ.get(\"WERKZEUG_RUN_MAIN\") == \"true\" or not app.debug:\n",
    "    init_app_once()\n",
    "\n",
    "# -----------------------------\n",
    "# PREPROCESO DE IMÁGENES.\n",
    "# -----------------------------\n",
    "def preprocess_image(file_storage):\n",
    "    # Adaptamos el tamaño de la imagen a la entrada del modelo y aplicamos el preprocess de ResNetV2.\n",
    "    in_shape = model.input_shape\n",
    "    if isinstance(in_shape, list):\n",
    "        in_shape = in_shape[0]\n",
    "    _, H, W, C = in_shape\n",
    "\n",
    "    img = Image.open(io.BytesIO(file_storage.read())).convert(\"RGB\")\n",
    "    img = img.resize((W, H))\n",
    "    arr = np.asarray(img, dtype=np.float32)\n",
    "    arr = resnet_preprocess(arr)\n",
    "    arr = np.expand_dims(arr, axis=0)\n",
    "    return arr\n",
    "\n",
    "def top_k_predictions(prob, k=5):\n",
    "    # Extraemos las k clases más probables junto con sus puntuaciones.\n",
    "    prob = np.array(prob).reshape(-1)\n",
    "    idxs = np.argsort(prob)[::-1][:k]\n",
    "    return [{\"class\": CLASS_NAMES[i], \"score\": float(prob[i])} for i in idxs]\n",
    "\n",
    "# -----------------------------\n",
    "# HELPERS PERSISTENCIA.\n",
    "# -----------------------------\n",
    "def save_prediction(image_name, top_class, score):\n",
    "    # Persistimos una predicción para histórico y análisis posterior.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        cur = con.execute(\n",
    "            \"INSERT INTO predictions(image_name, top_class, score, created_at) VALUES(?,?,?,?)\",\n",
    "            (image_name or \"\", top_class, float(score or 0.0), int(time.time()))\n",
    "        )\n",
    "        con.commit()\n",
    "        return cur.lastrowid\n",
    "\n",
    "def delete_prediction(pred_id: int):\n",
    "    # Eliminamos una predicción por id para limpieza del histórico.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        cur = con.execute(\"DELETE FROM predictions WHERE id = ?\", (pred_id,))\n",
    "        con.commit()\n",
    "        return cur.rowcount\n",
    "\n",
    "def list_predictions():\n",
    "    # Listamos predicciones recientes ordenadas por fecha de creación.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        cur = con.execute(\"SELECT id, image_name, top_class, score, created_at FROM predictions ORDER BY created_at DESC\")\n",
    "        rows = cur.fetchall()\n",
    "    return [dict(id=r[0], image_name=r[1], top_class=r[2], score=r[3], created_at=r[4]) for r in rows]\n",
    "\n",
    "def saved_classes(distinct_only=True):\n",
    "    # Obtenemos clases vistas previamente, con opción de deduplicar.\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        if distinct_only:\n",
    "            cur = con.execute(\"SELECT DISTINCT top_class FROM predictions\")\n",
    "            return [r[0] for r in cur.fetchall()]\n",
    "        else:\n",
    "            cur = con.execute(\"SELECT top_class FROM predictions\")\n",
    "            return [r[0] for r in cur.fetchall()]\n",
    "\n",
    "def _to_builtin_scalar(v):\n",
    "    # Convertimos escalares de NumPy a tipos nativos para JSON.\n",
    "    if v is None or isinstance(v, bool): return v\n",
    "    if isinstance(v, (np.integer,)):    return int(v)\n",
    "    if isinstance(v, (np.floating,)):   return float(v) if math.isfinite(float(v)) else None\n",
    "    if isinstance(v, (np.bool_,)):      return bool(v)\n",
    "    if isinstance(v, float):            return v if math.isfinite(v) else None\n",
    "    return v\n",
    "\n",
    "def json_sanitize(obj):\n",
    "    # Normalizamos estructuras para ser serializables en JSON de forma segura.\n",
    "    if obj is pd.NA: return None\n",
    "    if isinstance(obj, pd.DataFrame):   return _df_records_clean(obj)\n",
    "    if isinstance(obj, np.ndarray):     return [json_sanitize(x) for x in obj.tolist()]\n",
    "    if isinstance(obj, dict):           return {k: json_sanitize(v) for k, v in obj.items()}\n",
    "    if isinstance(obj, (list, tuple, set)):  return [json_sanitize(x) for x in obj]\n",
    "    if obj is None or isinstance(obj, bool): return obj\n",
    "    if isinstance(obj, (np.integer,)):       return int(obj)\n",
    "    if isinstance(obj, (np.floating, float)):\n",
    "        f = float(obj)\n",
    "        return f if math.isfinite(f) else None\n",
    "    return obj\n",
    "\n",
    "# -----------------------------\n",
    "# RECETAS + FILTROS.\n",
    "# -----------------------------\n",
    "def recipes_for_class(cls: str, limit: int = 20, ):\n",
    "    # Recuperamos recetas cuya categoría coincida con la clase y, si falla, buscamos por nombre.\n",
    "    df = RECIPES_DF\n",
    "    if df is None:\n",
    "        return []\n",
    "    mask_exact = df[\"Categoria\"].astype(str).str.strip().str.lower() == str(cls).strip().lower()\n",
    "    out = df.loc[mask_exact]\n",
    "\n",
    "    if out.empty:\n",
    "        out = df[df[\"Nombre\"].astype(str).str.contains(str(cls), case=False, na=False)]\n",
    "    cols = [c for c in [\"Id\", \"Categoria\", \"Nombre\", \"Valoracion\", \"Ingredientes\", \"Lista de ingredientes\"] if c in df.columns]\n",
    "    return _df_records_clean(out[cols].head(limit).reset_index(drop=True))\n",
    "\n",
    "def recipes_from_saved(per_class: int = 5, distinct_classes: bool = True):\n",
    "    # Para cada clase guardada, obtenemos un conjunto de recetas de referencia.\n",
    "    classes = saved_classes(distinct_only=distinct_classes)\n",
    "    result = {}\n",
    "    for cls in classes:\n",
    "        result[cls] = recipes_for_class(cls, limit=per_class)\n",
    "    return result\n",
    "\n",
    "# -----------------------------\n",
    "# ENDPOINTS.\n",
    "# -----------------------------\n",
    "@app.route(\"/\", methods=[\"GET\"])\n",
    "def home():\n",
    "    # Servimos la plantilla principal del frontend.\n",
    "    return render_template(\"index.html\")\n",
    "\n",
    "@app.route(\"/predict\", methods=[\"POST\"])\n",
    "def predict():\n",
    "    # Recibimos una imagen, preprocesamos, inferimos y guardamos la clase más probable como ingrediente.\n",
    "    try:\n",
    "        if \"image\" not in request.files:\n",
    "            return jsonify({\"ok\": False, \"error\": \"Falta el campo 'image' (archivo).\"}), 400\n",
    "\n",
    "        x = preprocess_image(request.files[\"image\"])\n",
    "        pred = model.predict(x)\n",
    "        probs = pred[0]\n",
    "\n",
    "        # Normalizamos de forma defensiva por si el modelo no devuelve una distribución válida.\n",
    "        s = float(np.sum(probs))\n",
    "        if not np.isfinite(s) or s <= 0 or s > 1.5:\n",
    "            e = np.exp(probs - np.max(probs))\n",
    "            probs = e / np.sum(e)\n",
    "\n",
    "        # Calculamos el top-k y seleccionamos la mejor predicción.\n",
    "        top5 = top_k_predictions(probs, k=min(5, len(CLASS_NAMES)))\n",
    "        selected = top5[0][\"class\"] if top5 else None\n",
    "\n",
    "        return jsonify({\"ok\": True, \"selected\": selected, \"top5\": top5})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"ok\": False, \"error\": str(e)}), 500\n",
    "\n",
    "# Guardamos una predicción simple sin asociar recetas.\n",
    "@app.route(\"/predictions\", methods=[\"POST\"])\n",
    "def create_prediction():\n",
    "    \"\"\"\n",
    "    Cuerpo JSON esperado.\n",
    "    {\n",
    "      \"image_name\": \"foto.jpg\",\n",
    "      \"class\": \"NombreDeClase\",\n",
    "      \"score\": 0.97\n",
    "    }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        top_class = data.get(\"class\")\n",
    "        if not top_class:\n",
    "            return jsonify({\"ok\": False, \"error\": \"Falta 'class' en el body.\"}), 400\n",
    "\n",
    "        image_name = data.get(\"image_name\") or \"\"\n",
    "        score = data.get(\"score\")\n",
    "        pred_id = save_prediction(image_name, top_class, score)\n",
    "        return jsonify({\"ok\": True, \"prediction_id\": pred_id})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"ok\": False, \"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/ingredients\", methods=[\"POST\"])\n",
    "def create_ingredient():\n",
    "    \"\"\"\n",
    "    Cuerpo JSON.\n",
    "    { \"name\": \"tomate\" }\n",
    "    \"\"\"\n",
    "    try:\n",
    "        data = request.get_json(force=True)\n",
    "        name = (data.get(\"name\") or \"\").strip()\n",
    "        if not name:\n",
    "            return jsonify({\"ok\": False, \"error\": \"Falta 'name'.\"}), 400\n",
    "        new_id = save_ingredient(name)\n",
    "        return jsonify({\"ok\": True, \"ingredient\": name, \"created\": bool(new_id)})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"ok\": False, \"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/ingredients\", methods=[\"GET\"])\n",
    "def get_ingredients():\n",
    "    # Devolvemos el listado de ingredientes guardados.\n",
    "    try:\n",
    "        items = list_ingredients()\n",
    "        return jsonify({\"ok\": True, \"items\": items})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"ok\": False, \"error\": str(e)}), 500\n",
    "\n",
    "# Permitimos nombres con espacios o acentos usando <path:name> y codificación URL en el cliente.\n",
    "@app.route(\"/ingredients/<path:name>\", methods=[\"DELETE\"])\n",
    "def remove_ingredient(name):\n",
    "    try:\n",
    "        name = (name or \"\").strip()\n",
    "        if not name:\n",
    "            return jsonify({\"ok\": False, \"error\": \"Falta nombre de ingrediente.\"}), 400\n",
    "        deleted = delete_ingredient(name)\n",
    "        if deleted == 0:\n",
    "            return jsonify({\"ok\": False, \"error\": \"No existe ese ingrediente.\"}), 404\n",
    "        return jsonify({\"ok\": True, \"deleted\": name})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"ok\": False, \"error\": str(e)}), 500\n",
    "\n",
    "@app.route(\"/predictions\", methods=[\"GET\"])\n",
    "def get_predictions():\n",
    "    # Exponemos las predicciones guardadas para depuración o UI.\n",
    "    try:\n",
    "        rows = list_predictions()\n",
    "        return jsonify({\"ok\": True, \"items\": rows})\n",
    "    except Exception as e:\n",
    "        return jsonify({\"ok\": False, \"error\": str(e)}), 500\n",
    "\n",
    "# Helper para construir diccionario de recetas desde ingredientes guardados.\n",
    "def recipes_from_ingredients(per_class: int = 5):\n",
    "    with sqlite3.connect(DB_PATH) as con:\n",
    "        cur = con.execute(\"SELECT name FROM ingredients\")\n",
    "        ingrs = [r[0] for r in cur.fetchall()]\n",
    "    result = {}\n",
    "    for ing in ingrs:\n",
    "        result[ing] = recipes_for_class(ing, limit=per_class)\n",
    "    return result\n",
    "\n",
    "@app.get(\"/allergy_choices\")\n",
    "def allergy_choices():\n",
    "    # Devolvemos la lista de claves de alérgenos con etiquetas legibles.\n",
    "    data = [{\"key\": k, \"label\": k.replace(\"_\", \" \").title()} for k in ALLERGENS.keys()]\n",
    "    return jsonify(data), 200\n",
    "\n",
    "# Reemplazo de /my_recipes con filtro por alergias y unión de ingredientes.\n",
    "@app.route(\"/my_recipes\", methods=[\"GET\", \"POST\"])\n",
    "def my_recipes():\n",
    "    try:\n",
    "        per_class = int(request.args.get(\"per_class\", \"5\"))\n",
    "\n",
    "        # Leemos alergias desde POST JSON o desde parámetros de consulta en GET.\n",
    "        selected_allergies = []\n",
    "        if request.method == \"POST\":\n",
    "            data = request.get_json(silent=True) or {}\n",
    "            selected_allergies = data.get(\"allergies\", []) or []\n",
    "        else:\n",
    "            selected_allergies = request.args.getlist(\"allergy\")\n",
    "            if not selected_allergies:\n",
    "                csv = request.args.get(\"allergies\")\n",
    "                if csv:\n",
    "                    selected_allergies = [s.strip() for s in csv.split(\",\") if s.strip()]\n",
    "\n",
    "        ingrs = get_saved_ingredients()\n",
    "\n",
    "        data_out = {}\n",
    "        meta = {\n",
    "            \"source\": \"ingredients_all\",\n",
    "            \"per_class\": per_class,\n",
    "            \"allergies\": selected_allergies,\n",
    "        }\n",
    "\n",
    "        if ingrs:\n",
    "            # Obtenemos recetas candidatas para todos los ingredientes guardados.\n",
    "            df = recipes_for_ingredients_df(ingrs, limit=per_class)\n",
    "\n",
    "            # Aplicamos exclusión por alérgenos seleccionados.\n",
    "            df = exclude_allergies_df(df, selected_allergies)\n",
    "\n",
    "            # Serializamos registros limpios y usamos una clave descriptiva.\n",
    "            recs = _df_records_clean(df)\n",
    "            key = \" + \".join(ingrs)\n",
    "            data_out[key] = recs\n",
    "            payload = {\"ok\": True, \"data\": data_out, \"meta\": meta}\n",
    "        else:\n",
    "            payload = {\"ok\": True, \"data\": {}, \"meta\": meta}\n",
    "\n",
    "        # Sanitizamos y devolvemos respuesta JSON con codificación UTF-8.\n",
    "        safe_payload = json_sanitize(payload)\n",
    "        body = json.dumps(safe_payload, ensure_ascii=False, allow_nan=False)\n",
    "        return Response(body, mimetype=\"application/json\")\n",
    "\n",
    "    except Exception as e:\n",
    "        err = {\"ok\": False, \"error\": str(e)}\n",
    "        return Response(json.dumps(err, ensure_ascii=False), mimetype=\"application/json\", status=500)\n",
    "\n",
    "# -----------------------------\n",
    "# MAIN.\n",
    "# -----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Iniciamos el servidor de desarrollo en localhost con recarga en debug.\n",
    "    app.run(host=\"127.0.0.1\", port=5000, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66732d-e513-4f36-9a25-29ec8f15a734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
