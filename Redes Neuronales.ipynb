{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b631fc0-b0ae-4780-adf7-3411cc56a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, random, pathlib\n",
    "from collections import defaultdict\n",
    "\n",
    "random.seed(1337)  # Fijamos la semilla para que las selecciones sean reproducibles.\n",
    "\n",
    "src_dir = \"PruebaDataset\"            # Indicamos la carpeta de origen con subcarpetas por clase.\n",
    "dst_dir = \"PruebaDataset_balanced\"   # Indicamos la carpeta de destino donde crearemos el dataset balanceado.\n",
    "extensions = {\".jpg\", \".jpeg\", \".png\", \".bmp\", \".gif\"}  # Definimos las extensiones de imagen permitidas.\n",
    "\n",
    "# 1) Recolectamos rutas por clase.\n",
    "files_by_class = defaultdict(list)\n",
    "for cls in sorted(os.listdir(src_dir)):\n",
    "    cpath = os.path.join(src_dir, cls)\n",
    "    if not os.path.isdir(cpath):\n",
    "        continue  # Ignoramos entradas que no sean directorios de clase.\n",
    "    for root, _, files in os.walk(cpath):\n",
    "        for f in files:\n",
    "            if pathlib.Path(f).suffix.lower() in extensions:\n",
    "                files_by_class[cls].append(os.path.join(root, f))  # Añadimos la ruta de cada imagen válida.\n",
    "\n",
    "# 2) Calculamos cuántas imágenes hay por clase y definimos N objetivo por clase.\n",
    "counts = {cls: len(v) for cls, v in files_by_class.items()}\n",
    "min_count = min(counts.values())  # Obtenemos el mínimo por si queremos usarlo como límite inferior.\n",
    "N = 100  # Definimos el número de muestras por clase, ajustable según disponibilidad por clase.\n",
    "\n",
    "print(\"Imágenes por clase:\", counts)  # Mostramos el conteo de imágenes por clase para diagnóstico.\n",
    "print(f\"Usando N={N} por clase\")  # Confirmamos el N elegido por clase.\n",
    "\n",
    "# 3) Creamos la carpeta de destino limpia.\n",
    "if os.path.exists(dst_dir):\n",
    "    shutil.rmtree(dst_dir)  # Eliminamos el destino si existía para evitar mezclas previas.\n",
    "os.makedirs(dst_dir, exist_ok=True)  # Creamos la carpeta de destino desde cero.\n",
    "\n",
    "# 4) Definimos helper para enlazar o copiar archivos según el sistema.\n",
    "def link_or_copy(src, dst):\n",
    "    try:\n",
    "        os.symlink(os.path.abspath(src), dst)  # Creamos un enlace simbólico para ahorrar espacio cuando sea posible.\n",
    "    except Exception:\n",
    "        shutil.copy2(src, dst)  # Copiamos físicamente el archivo si no podemos crear el enlace.\n",
    "\n",
    "# 5) Seleccionamos N imágenes aleatorias por clase y las escribimos en el destino.\n",
    "for cls, paths in files_by_class.items():\n",
    "    random.shuffle(paths)  # Barajamos las rutas para muestrear aleatoriamente.\n",
    "    keep = paths[:N]  # Tomamos las primeras N rutas tras el barajado.\n",
    "    out_cls = os.path.join(dst_dir, cls)\n",
    "    os.makedirs(out_cls, exist_ok=True)  # Creamos la subcarpeta de la clase en el destino.\n",
    "    for i, p in enumerate(keep):\n",
    "        ext = pathlib.Path(p).suffix.lower()\n",
    "        dst_path = os.path.join(out_cls, f\"{cls}_{i:05d}{ext}\")  # Generamos un nombre de archivo estable y ordenable.\n",
    "        link_or_copy(p, dst_path)  # Enlazamos o copiamos la imagen al destino.\n",
    "\n",
    "print(\"✓ Dataset balanceado creado en:\", dst_dir)  # Indicamos finalización y la ruta del dataset balanceado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23292b01-e1b4-4598-85d7-98195d3f1fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11850 images belonging to 120 classes.\n",
      "Clases detectadas en TRAIN: 120\n",
      "['Aguacate', 'Anacardos', 'Banana', 'Berberechos', 'Calabacín', 'Calabaza', 'Canela', 'Canónigos', 'Carne Cerdo', 'Carne Conejo', 'Carne Cordero', 'Carne Pavo', 'Carne Ternera', 'Carne picada', 'Chorizo', 'Cilantro', 'Clavo', 'Coliflor', 'Curry', 'Cuscus', 'Espaguetis', 'Espinacas', 'Fideos', 'Gambas', 'Garbanzos', 'Grosellas', 'Guisantes', 'Hierbabuena', 'Jamon iberico', 'Levadura', 'Lima', 'Limón', 'Mantequilla', 'Mayonesa', 'Mejillones', 'Melocotones', 'Melón', 'Membrillo', 'Merluza', 'Miel', 'Mora', 'Morcilla', 'Mostaza', 'Naranja', 'Nata líquida', 'Nueces', 'Nuez moscada', 'Níscalos', 'Orégano', 'Pechuga de pollo', 'Salmon', 'Tomillo', 'Zanahoria', 'aceitunas', 'acelgas', 'ajo', 'albahaca', 'alcachofa', 'almejas', 'almendras', 'apio', 'arroz', 'atun fresco', 'avellanas', 'azucar', 'bacalao', 'berenjena', 'boniato', 'boquerones', 'brocoli', 'calamares', 'cebollas', 'cerezas', 'champinones', 'chirimoya', 'chocolate', 'col', 'huevos', 'judías verdes', 'langostinos', 'laurel', 'leche', 'lechuga', 'lentejas', 'manzana', 'pan rallado', 'pasta macarrones', 'patata', 'pepino', 'pera', 'perejil', 'pimentón', 'pimienta blanca', 'pimienta negra', 'pimiento amarillo', 'pimiento rojo', 'pimiento verde', 'pistacho', 'piñones', 'platano', 'puerro', 'pulpo', 'queso fresco', 'queso manchego', 'quinoa', 'rabanitos', 'romero', 'rucula', 'sal', 'sandia', 'sardinas', 'sepia', 'setas variadas', 'tomate', 'tomate cherry', 'uva', 'vinagre balsamico', 'vino blanco', 'vino tinto', 'yogur natural']\n",
      "Found 11850 images belonging to 120 classes.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ resnet50v2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │      <span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">245,880</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ resnet50v2 (\u001b[38;5;33mFunctional\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │      \u001b[38;5;34m23,564,800\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)                 │         \u001b[38;5;34m245,880\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,810,680</span> (90.83 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,810,680\u001b[0m (90.83 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">245,880</span> (960.47 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m245,880\u001b[0m (960.47 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,564,800</span> (89.89 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,564,800\u001b[0m (89.89 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Entrenamiento inicial...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jose\\anaconda3\\envs\\Proyecto\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "C:\\Users\\Jose\\anaconda3\\envs\\Proyecto\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m 56/371\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9:01\u001b[0m 2s/step - accuracy: 0.0402 - loss: 5.2050"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 1) Configuración reproducible.\n",
    "# -----------------------------------------------------------------------------\n",
    "SEED = 1337\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # Silenciamos los logs de TensorFlow para mantener la salida limpia.\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Generadores de datos (consistentes con ResNet50V2).\n",
    "# -----------------------------------------------------------------------------\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input as resnet_preprocess\n",
    "\n",
    "img_size = (256, 256)\n",
    "batch_size = 32\n",
    "target_shape = (*img_size, 3)\n",
    "\n",
    "# Creamos el generador de datos con aumentación para el entrenamiento.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    preprocessing_function=resnet_preprocess\n",
    ")\n",
    "\n",
    "# Creamos el generador de datos para validación solo con preprocesamiento.\n",
    "valid_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=resnet_preprocess\n",
    ")\n",
    "\n",
    "# Cargamos las imágenes de entrenamiento desde la carpeta correspondiente.\n",
    "data_gen_entrenamiento = train_datagen.flow_from_directory(\n",
    "    \"Dataset\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\"\n",
    ")\n",
    "\n",
    "# Obtenemos los nombres de las clases y la cantidad total detectada.\n",
    "class_names = list(data_gen_entrenamiento.class_indices.keys())\n",
    "num_classes = len(class_names)\n",
    "print(\"Clases detectadas en TRAIN:\", num_classes)\n",
    "print(class_names)\n",
    "\n",
    "#with open(\"class_names.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "#    json.dump(class_names, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# Creamos el generador de validación, forzando el mismo orden de clases.\n",
    "data_gen_pruebas = valid_datagen.flow_from_directory(\n",
    "    \"Dataset\",\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=SEED,\n",
    "    class_mode=\"categorical\",\n",
    "    color_mode=\"rgb\",\n",
    "    classes=class_names\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Definición del modelo (ResNet50V2 base + capa de clasificación).\n",
    "# -----------------------------------------------------------------------------\n",
    "def crear_modelo_resnet(input_shape, n_classes):\n",
    "    from tensorflow.keras.applications import ResNet50V2\n",
    "\n",
    "    # Cargamos la base preentrenada sin la parte superior.\n",
    "    base = ResNet50V2(\n",
    "        include_top=False,\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=input_shape,\n",
    "        pooling=\"avg\",\n",
    "        name=\"resnet50v2\"\n",
    "    )\n",
    "    base.trainable = False  # Mantenemos la base congelada inicialmente.\n",
    "\n",
    "    # Definimos la arquitectura del modelo completo.\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    x = base(inputs, training=False)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(n_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # Compilamos el modelo con Adam y entropía cruzada categórica.\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Creación del modelo.\n",
    "# -----------------------------------------------------------------------------\n",
    "model = crear_modelo_resnet(target_shape, num_classes)\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 5) Definición de callbacks.\n",
    "# -----------------------------------------------------------------------------\n",
    "callbacks_iniciales = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=8,\n",
    "        restore_best_weights=True,\n",
    "        min_delta=0.001\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\",\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=1,\n",
    "        min_lr=1e-7\n",
    "    )\n",
    "]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 6) Entrenamiento inicial con la base congelada.\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"🚀 Entrenamiento inicial...\")\n",
    "historial = model.fit(\n",
    "    data_gen_entrenamiento,\n",
    "    epochs=30,\n",
    "    validation_data=data_gen_pruebas,\n",
    "    callbacks=callbacks_iniciales,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 7) Fine-tuning: descongelamos las capas superiores de la base.\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"🔧 Fine-tuning...\")\n",
    "\n",
    "base_model = model.get_layer(\"resnet50v2\")\n",
    "N = 30  # Número de capas superiores a descongelar.\n",
    "for layer in base_model.layers[-N:]:\n",
    "    if not isinstance(layer, layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Recompilamos con una tasa de aprendizaje más baja.\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "callbacks_ft = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_accuracy\",\n",
    "        patience=4,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "]\n",
    "\n",
    "historial_ft = model.fit(\n",
    "    data_gen_entrenamiento,\n",
    "    epochs=10,\n",
    "    validation_data=data_gen_pruebas,\n",
    "    callbacks=callbacks_ft,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 8) Evaluación final del modelo.\n",
    "# -----------------------------------------------------------------------------\n",
    "print(\"📊 Evaluación final en validación:\")\n",
    "val_loss, val_acc = model.evaluate(data_gen_pruebas, verbose=0)\n",
    "print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
    "\n",
    "#model.save(\"modelo.h5\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 9) Visualización de las curvas de entrenamiento.\n",
    "# -----------------------------------------------------------------------------\n",
    "acc = historial.history.get('accuracy', []) + historial_ft.history.get('accuracy', [])\n",
    "val_acc = historial.history.get('val_accuracy', []) + historial_ft.history.get('val_accuracy', [])\n",
    "loss = historial.history.get('loss', []) + historial_ft.history.get('loss', [])\n",
    "val_loss_hist = historial.history.get('val_loss', []) + historial_ft.history.get('val_loss', [])\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(acc)\n",
    "plt.plot(val_acc)\n",
    "plt.title('Precisión del modelo.')\n",
    "plt.ylabel('Precisión.')\n",
    "plt.xlabel('Época.')\n",
    "plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(loss)\n",
    "plt.plot(val_loss_hist)\n",
    "plt.title('Pérdida del modelo.')\n",
    "plt.ylabel('Pérdida.')\n",
    "plt.xlabel('Época.')\n",
    "plt.legend(['Entrenamiento', 'Validación'], loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 10) Cálculo de métricas por clase y matriz de confusión.\n",
    "# -----------------------------------------------------------------------------\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Obtenemos las predicciones sobre el conjunto de validación.\n",
    "y_true = data_gen_pruebas.classes\n",
    "y_prob = model.predict(data_gen_pruebas, verbose=1)\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "# Generamos el informe de clasificación por clase.\n",
    "labels_all = np.arange(num_classes)\n",
    "\n",
    "print(\"\\n📄 Classification report por clase:\")\n",
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    labels=labels_all,\n",
    "    target_names=class_names,\n",
    "    digits=4,\n",
    "    zero_division=0\n",
    "))\n",
    "\n",
    "# Calculamos la matriz de confusión.\n",
    "cm = confusion_matrix(y_true, y_pred, labels=labels_all)\n",
    "print(\"\\n🔢 Matriz de confusión (filas=verdadero, columnas=predicho):\")\n",
    "print(cm)\n",
    "\n",
    "# Calculamos la exactitud por clase.\n",
    "cm_diag = np.diag(cm)\n",
    "support = cm.sum(axis=1)\n",
    "acc_per_class = cm_diag / np.maximum(support, 1)\n",
    "\n",
    "print(\"\\n✅ Exactitud por clase:\")\n",
    "for name, acc_c, sup in zip(class_names, acc_per_class, support):\n",
    "    print(f\" - {name:<20s} acc={acc_c:7.4f}  soporte={sup}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a7f9c-3d01-4166-a34d-eae08285df76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
